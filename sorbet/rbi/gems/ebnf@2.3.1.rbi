# typed: true

# DO NOT EDIT MANUALLY
# This is an autogenerated file for types exported from the `ebnf` gem.
# Please instead update this file by running `bin/tapioca gem ebnf`.

# This file is automatically generated by ebnf version 2.0.0
# Derived from etc/abnf-core.ebnf
module ABNFCore; end

ABNFCore::RULES = T.let(T.unsafe(nil), Array)

# This file is automatically generated by ebnf version 2.0.0
# Derived from abnf.ebnf
module ABNFMeta; end

ABNFMeta::RULES = T.let(T.unsafe(nil), Array)

# Serialize ruleset back to EBNF
module EBNF
  class << self
    # Parse the given EBNF `query` input.
    #
    # @example
    #   ebnf = EBNF.parse(input)
    # @param input [#read, String, #to_s]
    # @param options [Hash{Symbol => Object}]
    # @raise [Exception] on invalid input
    # @return [EBNF::Base]
    def parse(input, **options); end
  end
end

class EBNF::ABNF
  include ::EBNF::PEG::Parser
  extend ::EBNF::PEG::Parser::ClassMethods

  # ## Parser invocation.
  # On start, yield ourselves if a block is given, otherwise, return this parser instance
  #
  # @option options
  # @param input [#read, #to_s]
  # @param options [Hash{Symbol => Object}]
  # @return [EBNFParser]
  def initialize(input, **options); end

  # The AST includes the parsed rules along with built-in rules for ABNF used within the parsed grammar.
  #
  # @return [Array<EBNF::Rule>]
  def ast; end

  # Hash of generated {EBNF::Rule} objects by symbol
  #
  # @return [Hash{Symbol => EBNF::Rule}]
  def parsed_rules; end

  private

  # Generate a combination of seq and string to represent a sequence of characters
  #
  # @param characters [Array<String>]
  # @return [String, Array]
  def hex_or_string(characters); end
end

# Regular expressions for both "Core" and ABNF-specific terminals.
EBNF::ABNF::ALPHA = T.let(T.unsafe(nil), Regexp)

EBNF::ABNF::COMMENT = T.let(T.unsafe(nil), Regexp)
EBNF::ABNF::CRLF = T.let(T.unsafe(nil), Regexp)
EBNF::ABNF::C_NL = T.let(T.unsafe(nil), Regexp)
EBNF::ABNF::C_WSP = T.let(T.unsafe(nil), Regexp)
EBNF::ABNF::VCHAR = T.let(T.unsafe(nil), Regexp)
EBNF::ABNF::WSP = T.let(T.unsafe(nil), Regexp)

module EBNF::BNF
  # Transform EBNF Rule set to BNF:
  #
  #   * Add rule [0] (_empty rule (seq))
  #   * Transform each rule into a set of rules that are just BNF, using {Rule#to_bnf}.
  #
  # @return [ENBF] self
  def make_bnf; end
end

class EBNF::Base
  include ::EBNF::BNF
  include ::EBNF::LL1
  include ::EBNF::Native
  include ::EBNF::PEG

  # Parse the string or file input generating an abstract syntax tree
  # in S-Expressions (similar to SPARQL SSE)
  #
  # @option options
  # @option options
  # @param input [#read, #to_s]
  # @param format [Symbol] (:ebnf)
  #   Format of input, one of `:abnf`, `:ebnf`, `:isoebnf`, `:isoebnf`, `:native`, or `:sxp`.
  #   Use `:native` for the native EBNF parser, rather than the PEG parser.
  # @param options [Hash{Symbol => Object}]
  # @return [Base] a new instance of Base
  def initialize(input, format: T.unsafe(nil), **options); end

  # Abstract syntax tree from parse
  #
  # @return [Array<Rule>]
  def ast; end

  # Progress output when debugging
  #
  # @overload debug
  # @overload debug
  # @yieldreturn [String] added to message
  def debug(*args, **options); end

  def depth; end
  def dup; end

  # Iterate over each rule or terminal, except empty
  #
  # @param kind [:termina, :rule]
  # @yield rule
  # @yieldparam rule [Rule]
  def each(kind, &block); end

  # Error output
  def error(*args, **options); end

  # Grammar errors, or errors found genering parse tables
  #
  # @return [Array<String>]
  def errors; end

  # Grammar errors, or errors found genering parse tables
  #
  # @return [Array<String>]
  def errors=(_arg0); end

  # Find a rule given a symbol
  #
  # @param sym [Symbol]
  # @return [Rule]
  def find_rule(sym); end

  # Progress output, less than debugging
  def progress(*args, **options); end

  # Renumber, rule identifiers
  def renumber!; end

  # Output formatted EBNF as HTML
  #
  # @param format [:abnf, :ebnf, :isoebnf] (:ebnf)
  # @param validate [Boolean] (false) validate generated HTML.
  # @return [String]
  def to_html(format: T.unsafe(nil), validate: T.unsafe(nil)); end

  # Output Ruby parser files
  #
  # @param output [IO, StringIO]
  # @param grammarFile [String]
  # @param mod_name [String] ('Meta')
  def to_ruby(output = T.unsafe(nil), grammarFile: T.unsafe(nil), mod_name: T.unsafe(nil), **options); end

  # Output formatted EBNF
  #
  # @param format [:abnf, :ebnf, :isoebnf] (:ebnf)
  # @return [String]
  def to_s(format: T.unsafe(nil)); end

  # Write out parsed syntax string as an S-Expression
  #
  # @return [String]
  def to_sxp(**options); end

  # Write out syntax tree as Turtle
  #
  # @param prefix [String] for language
  # @param ns [String] URI for language
  # @return [String]
  def to_ttl(prefix = T.unsafe(nil), ns = T.unsafe(nil)); end

  # Is the grammar valid?
  #
  # Uses `#validate!` and catches `RangeError`
  #
  # @return [Boolean]
  def valid?; end

  # Validate the grammar.
  #
  # Makes sure that rules reference either strings or other defined rules.
  #
  # @raise [RangeError]
  def validate!; end
end

class EBNF::ISOEBNF
  include ::EBNF::PEG::Parser
  extend ::EBNF::PEG::Parser::ClassMethods

  # ## Parser invocation.
  # On start, yield ourselves if a block is given, otherwise, return this parser instance
  #
  # @option options
  # @param input [#read, #to_s]
  # @param options [Hash{Symbol => Object}]
  # @return [EBNFParser]
  def initialize(input, **options, &block); end

  # Abstract syntax tree from parse
  #
  # @return [Array<EBNF::Rule>]
  def ast; end
end

EBNF::ISOEBNF::FIRST_TERMINAL_CHARACTER = T.let(T.unsafe(nil), Regexp)
EBNF::ISOEBNF::SECOND_TERMINAL_CHARACTER = T.let(T.unsafe(nil), Regexp)
EBNF::ISOEBNF::SPECIAL_SEQUENCE_CHARACTER = T.let(T.unsafe(nil), Regexp)
EBNF::ISOEBNF::TERMINAL_CHARACTER = T.let(T.unsafe(nil), Regexp)

# The base for terminal-character, which omits "'", '"', and '?'.
# Could be more optimized, and one might quible
# with the overly-strictly defined character set,
# but it is correct.
EBNF::ISOEBNF::TERMINAL_CHARACTER_BASE = T.let(T.unsafe(nil), Regexp)

# This module extends {EBNF::Base} to create metadata including _branch_,  [First/Follow][], and other tables which is used by {EBNF::LL1::Parser} to recognize examples of the associated grammar.
#
# Branch Table
#
#  The Branch table is a hash mapping production rules to a hash relating terminals appearing in input to sequence of productions to follow when the corresponding input terminal is found. This allows either the `seq` primitive, where all terminals map to the same sequence of productions, or the `alt` primitive, where each terminal may map to a different production.
#
#      BRANCH = {
#        :alt => {
#          "(" => [:seq, :_alt_1],
#          :HEX => [:seq, :_alt_1],
#          :O_RANGE => [:seq, :_alt_1],
#          :RANGE => [:seq, :_alt_1],
#          :STRING1 => [:seq, :_alt_1],
#          :STRING2 => [:seq, :_alt_1],
#          :SYMBOL => [:seq, :_alt_1],
#        },
#        ...
#        :declaration => {
#          "@pass" => [:pass],
#          "@terminals" => ["@terminals"],
#        },
#        ...
#      }
#
#  In this case the `alt` rule is `seq ('|' seq)*` can happen when any of the specified tokens appears on the input stream. The all cause the same token to be passed to the `seq` rule and follow with `_alt_1`, which handles the `('|' seq)*` portion of the rule, after the first sequence is matched.
#
#  The `declaration` rule is `@terminals' | pass` using the `alt` primitive determining the production to run based on the terminal appearing on the input stream. Eventually, a terminal production is found and the token is consumed.
#
# First/Follow Table
#
#  The [First/Follow][] table is a hash mapping production rules to the terminals that may proceed or follow the rule. For example:
#
#      FIRST = {
#        :alt => [
#          :HEX,
#          :SYMBOL,
#          :RANGE,
#          :O_RANGE,
#          :STRING1,
#          :STRING2,
#          "("],
#        ...
#      }
#
# Terminals Table
#
#  This table is a simple list of the terminal productions found in the grammar. For example:
#
#      TERMINALS = ["(", ")", "-",
#        "@pass", "@terminals",
#         :HEX, :LHS, :O_RANGE,:POSTFIX,
#        :RANGE, :STRING1, :STRING2, :SYMBOL,"|"
#      ].freeze
#
# Cleanup Table
#
#  This table identifies productions which used EBNF rules, which are transformed to BNF for actual parsing. This allows the parser, in some cases, to reproduce *star*, *plus*, and *opt* rule matches. For example:
#
#      CLEANUP = {
#        :_alt_1 => :star,
#        :_alt_3 => :merge,
#        :_diff_1 => :opt,
#        :ebnf => :star,
#        :_ebnf_2 => :merge,
#        :_postfix_1 => :opt,
#        :seq => :plus,
#        :_seq_1 => :star,
#        :_seq_2 => :merge,
#      }.freeze
#
#  In this case the `ebnf` rule was `(declaration | rule)*`. As BNF does not support a star operator, this is decomposed into a set of rules using `alt` and `seq` primitives:
#
#      ebnf    ::= _empty _ebnf_2
#      _ebnf_1 ::= declaration | rule
#      _ebnf_2 ::= _ebnf_1 ebnf
#      _ebnf_3 ::= ebnf
#
#  The `_empty` production matches an empty string, so allows for now value. `_ebnf_2` matches `declaration | rule` (using the `alt` primitive) followed by `ebnf`, creating a sequence of zero or more `declaration` or `alt` members.
#
# [First/Follow]: https://en.wikipedia.org/wiki/LL_parser#Constructing_an_LL.281.29_parsing_table
module EBNF::LL1
  # Branch table, represented as a recursive hash.
  # The table is indexed by rule symbol, which in-turn references a hash of terminals (which are the first terminals of the production), which in turn reference the sequence of rules that follow, given that terminal as input
  #
  # @return [Hash{Symbol => Hash{String, Symbol => Array<Symbol>}}]
  def branch; end

  # Generate parser tables, {#branch}, {#first}, {#follow}, and {#terminals}
  def build_tables; end

  # EBNF Cleanup table
  #
  # The list of terminals used in the grammar.
  #
  # @return [Hash{Symbol => Symbol}]
  def cleanup; end

  # First table
  #
  # @return [Hash{Symbol => Array<String, Symbol>}]
  def first; end

  # Create first/follow for each rule using techniques defined for LL(1) parsers.
  #
  # This takes rules which have transformed into BNF and adds first/follow and otehr information to the rules to allow the generation of metadata tables used for driving a parser.
  #
  # Given an initial rule in EBNF:
  #
  #     (rule enbf "1" (star declaration rule))
  #
  # The BNF transformation becomes:
  #
  #     (rule ebnf "1" (alt _empty _ebnf_2))
  #     (rule _ebnf_1 "1.1" (alt declaration rule))
  #     (rule _ebnf_2 "1.2" (seq _ebnf_1 ebnf))
  #     (rule _ebnf_3 "1.3" (seq ebnf))
  #
  # After running this method, the rules are annotated with first/follow and cleanup rules:
  #
  #     (rule ebnf "1"
  #      (start #t)
  #      (first "@pass" "@terminals" LHS _eps)
  #      (follow _eof)
  #      (cleanup star)
  #      (alt _empty _ebnf_2))
  #     (rule _ebnf_1 "1.1"
  #      (first "@pass" "@terminals" LHS)
  #      (follow "@pass" "@terminals" LHS _eof)
  #      (alt declaration rule))
  #     (rule _ebnf_2 "1.2"
  #      (first "@pass" "@terminals" LHS)
  #      (follow _eof)
  #      (cleanup merge)
  #      (seq _ebnf_1 ebnf))
  #     (rule _ebnf_3 "1.3" (first "@pass" "@terminals" LHS _eps) (follow _eof) (seq ebnf))
  #
  # @param starts [Array<Symbol>] Set of symbols which are start rules
  # @return [EBNF] self
  # @see https://en.wikipedia.org/wiki/LL_parser#Constructing_an_LL.281.29_parsing_table
  def first_follow(*starts); end

  # Follow table
  #
  # @return [Hash{Symbol => Array<String, Symbol>}]
  def follow; end

  # Generate an output table in Ruby format
  #
  # @param io [IO, StringIO]
  # @param name [String] of the table constant
  # @param table [String] to output, one of {#branch}, {#first}, {#follow}, {#cleanup} or {#terminals}
  # @param indent [Integer] = 0
  def outputTable(io, name, table, indent = T.unsafe(nil)); end

  # Pass expression
  #
  # A Terminal symbol used for skipping whitespace and comments
  #
  # @return [Symbol, String]
  def pass; end

  # Start symbol
  #
  # The rule which starts the grammar
  #
  # @return [Symbol]
  def start; end

  # Terminal table
  #
  # The list of terminals used in the grammar.
  #
  # @return [Array<String, Symbol>]
  def terminals; end

  # Output Ruby parser files for LL(1) parsing
  #
  # @param output [IO, StringIO]
  def to_ruby_ll1(output, **options); end

  private

  def do_production(lhs); end
end

# A lexical analyzer
#
# @example Tokenizing a Turtle string
#   terminals = [
#   [:BLANK_NODE_LABEL, %r(_:(#{PN_LOCAL}))],
#   ...
#   ]
#   ttl = "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> ."
#   lexer = EBNF::LL1::Lexer.tokenize(ttl, terminals)
#   lexer.each_token do |token|
#   puts token.inspect
#   end
# @example Tokenizing and returning a token stream
#   lexer = EBNF::LL1::Lexer.tokenize(...)
#   while :some-condition
#   token = lexer.first # Get the current token
#   token = lexer.shift # Get the current token and shift to the next
#   end
# @example Handling error conditions
#   begin
#   EBNF::LL1::Lexer.tokenize(query)
#   rescue EBNF::LL1::Lexer::Error => error
#   warn error.inspect
#   end
# @see https://en.wikipedia.org/wiki/Lexical_analysis
class EBNF::LL1::Lexer
  include ::Enumerable
  include ::EBNF::Unescape

  # Initializes a new lexer instance.
  #
  # @option options
  # @option options[Integer]
  # @option options[Integer]
  # @param options[Integer] [Hash] a customizable set of options
  # @param terminals [Array<Array<Symbol, Regexp>, Terminal>] Array of symbol, regexp pairs used to match terminals.
  #   If the symbol is nil, it defines a Regexp to match string terminals.
  # @param input [String, #to_s]
  # @param options [Hash{Symbol => Object}]
  # @raise [Error]
  # @return [Lexer] a new instance of Lexer
  def initialize(input = T.unsafe(nil), terminals = T.unsafe(nil), **options); end

  # Enumerates each token in the input string.
  #
  # @return [Enumerator]
  # @yield [token]
  # @yieldparam token [Token]
  def each(&block); end

  # Enumerates each token in the input string.
  #
  # @return [Enumerator]
  # @yield [token]
  # @yieldparam token [Token]
  def each_token(&block); end

  # Returns first token in input stream
  #
  # @param types [Array[Symbol]] Optional set of types for restricting terminals examined
  # @return [Token]
  def first(*types); end

  # The current input string being processed.
  #
  # @return [String]
  def input; end

  # The current input string being processed.
  #
  # @return [String]
  def input=(_arg0); end

  # The current line number (one-based).
  #
  # @return [Integer]
  def lineno; end

  # Any additional options for the lexer.
  #
  # @return [Hash]
  def options; end

  # Skip input until a token is matched
  #
  # @param types [Array[Symbol]] Optional set of types for restricting terminals examined
  # @return [Token]
  def recover(*types); end

  # Returns first token and shifts to next
  #
  # @return [Token]
  def shift; end

  # Returns `true` if the input string is lexically valid.
  #
  # To be considered valid, the input string must contain more than zero
  # terminals, and must not contain any invalid terminals.
  #
  # @return [Boolean]
  def valid?; end

  # @return [Regexp] defines whitespace, including comments, otherwise whitespace must be explicit in terminals
  def whitespace; end

  protected

  # Return the matched token.
  #
  # If the token was matched with a case-insensitive regexp,
  # track this with the resulting {Token}, so that comparisons
  # with that token are also case insensitive
  #
  # @param types [Array[Symbol]] Optional set of types for restricting terminals examined
  # @return [Token]
  def match_token(*types); end

  # @return [StringScanner]
  def scanner; end

  # Skip whitespace, as defined through input options or defaults
  def skip_whitespace; end

  # Constructs a new token object annotated with the current line number.
  #
  # The parser relies on the type being a symbolized URI and the value being
  # a string, if there is no type. If there is a type, then the value takes
  # on the native representation appropriate for that type.
  #
  # @param type [Symbol]
  # @param value [String] Scanner instance with access to matched groups
  # @param options [Hash{Symbol => Object}]
  # @return [Token]
  def token(type, value, **options); end

  class << self
    # Tokenizes the given `input` string or stream.
    #
    # @param input [String, #to_s]
    # @param terminals [Array<Array<Symbol, Regexp>>] Array of symbol, regexp pairs used to match terminals.
    #   If the symbol is nil, it defines a Regexp to match string terminals.
    # @param options [Hash{Symbol => Object}]
    # @raise [Lexer::Error] on invalid input
    # @return [Lexer]
    # @yield [lexer]
    # @yieldparam lexer [Lexer]
    def tokenize(input, terminals, **options, &block); end

    # Returns a copy of the given `input` string with all `\uXXXX` and
    # `\UXXXXXXXX` Unicode codepoint escape sequences replaced with their
    # unescaped UTF-8 character counterparts.
    #
    # @param string [String]
    # @return [String]
    # @see https://www.w3.org/TR/rdf-sparql-query/#codepointEscape
    def unescape_codepoints(string); end

    # Returns a copy of the given `input` string with all string escape
    # sequences (e.g. `\n` and `\t`) replaced with their unescaped UTF-8
    # character counterparts.
    #
    # @param input [String]
    # @return [String]
    # @see https://www.w3.org/TR/rdf-sparql-query/#grammarEscapes
    def unescape_string(input); end
  end
end

# Raised for errors during lexical analysis.
#
# @example Raising a lexer error
#   raise EBNF::LL1::Lexer::Error.new(
#   "invalid token '%' on line 10",
#   input: query, token: '%', lineno: 9)
# @see https://ruby-doc.org/core/classes/StandardError.html
class EBNF::LL1::Lexer::Error < ::StandardError
  # Initializes a new lexer error instance.
  #
  # @option options
  # @option options
  # @option options
  # @param message [String, #to_s]
  # @param options [Hash{Symbol => Object}]
  # @return [Error] a new instance of Error
  def initialize(message, **options); end

  # The input string associated with the error.
  #
  # @return [String]
  def input; end

  # The line number where the error occurred.
  #
  # @return [Integer]
  def lineno; end

  # The invalid token which triggered the error.
  #
  # @return [String]
  def token; end
end

# Terminal class, representing the terminal identifier and
# matching regular expression. Optionally, a Terminal may include
# a map to turn case-insensitively matched terminals into their
# canonical form
class EBNF::LL1::Lexer::Terminal
  # @option options
  # @option options
  # @option options
  # @param type [Symbol, nil]
  # @param regexp [Regexp]
  # @param options [Hash{Symbol => Object}]
  # @return [Terminal] a new instance of Terminal
  def initialize(type, regexp, **options); end

  def ==(other); end

  # Map a terminal to it's canonical form. If there is no
  # map, `value` is returned. `value` is unescaped if there
  # is no canonical mapping, and the `:unescape` option is set.
  #
  # @param value [String] value to canonicalize
  # @return [String]
  def canonicalize(value); end

  # Returns the value of attribute partial_regexp.
  def partial_regexp; end

  # Returns the value of attribute regexp.
  def regexp; end

  # Returns the value of attribute type.
  def type; end

  protected

  # Perform string and codepoint unescaping if defined for this terminal
  #
  # @param string [String]
  # @return [String]
  def unescape(string); end
end

# Represents a lexer token.
#
# @example Creating a new token
#   token = EBNF::LL1::Lexer::Token.new(:LANGTAG, "en")
#   token.type   #=> :LANGTAG
#   token.value  #=> "en"
# @see https://en.wikipedia.org/wiki/Lexical_analysis#Token
class EBNF::LL1::Lexer::Token
  # Initializes a new token instance.
  #
  # @option options
  # @param type [Symbol]
  # @param value [String]
  # @param options [Hash{Symbol => Object}]
  # @return [Token] a new instance of Token
  def initialize(type, value, **options); end

  # Returns `true` if the given `value` matches either the type or value
  # of this token.
  #
  # @example Matching using the symbolic type
  #   EBNF::LL1::Lexer::Token.new(:NIL) === :NIL     #=> true
  # @example Matching using the string value
  #   EBNF::LL1::Lexer::Token.new(nil, "{") === "{"  #=> true
  # @param value [Symbol, String]
  # @return [Boolean]
  def ===(value); end

  # Returns the attribute named by `key`.
  #
  # @param key [Symbol]
  # @return [Object]
  def [](key); end

  # Returns a developer-friendly representation of this token.
  #
  # @return [String]
  def inspect; end

  # The line number where the token was encountered.
  #
  # @return [Integer]
  def lineno; end

  # Any additional options for the token.
  #
  # @return [Hash]
  def options; end

  # Returns type, if not nil, otherwise value
  def representation; end

  # Returns an array representation of this token.
  #
  # @return [Array]
  def to_a; end

  # Returns a hash table representation of this token.
  #
  # @return [Hash]
  def to_hash; end

  # Readable version of token
  def to_s; end

  # The token's symbol type.
  #
  # @return [Symbol]
  def type; end

  # The token's value.
  #
  # @return [String]
  def value; end
end

# A Generic LL1 parser using a lexer and branch tables defined using the SWAP tool chain (modified).
#
#  # Creating terminal definitions and parser rules to parse generated grammars
#
#  The parser is initialized to callbacks invoked on entry and exit
#  to each `terminal` and `production`. A trivial parser loop can be described as follows:
#
#      require 'ebnf/ll1/parser'
#      require 'meta'
#
#      class Parser
#        include Meta
#        include EBNF::LL1::Parser
#
#        terminal(:SYMBOL, /([a-z]|[A-Z]|[0-9]|_)+/) do |prod, token, input|
#          # Add data based on scanned token to input
#          input[:symbol] = token.value
#        end
#
#        start_production(:rule) do |input, current, callback|
#          # Process on start of production
#          # Set state for entry into recursed rules through current
#
#          # Callback to parser loop with callback
#        end
#
#        production(:rule) do |input, current, callback|
#          # Process on end of production
#          # return results in input, retrieve results from recursed rules in current
#
#          # Callback to parser loop with callback
#        end
#
#        def initialize(input)
#          parse(input, start_symbol,
#            branch: BRANCH,
#            first: FIRST,
#            follow: FOLLOW,
#            cleanup: CLEANUP
#          ) do |context, *data|
#            # Process calls from callback from productions
#
#          rescue ArgumentError, RDF::LL1::Parser::Error => e
#            progress("Parsing completed with errors:\n\t#{e.message}")
#            raise RDF::ReaderError, e.message if validate?
#          end
module EBNF::LL1::Parser
  mixes_in_class_methods ::EBNF::LL1::Parser::ClassMethods

  # Add values to production data, values aranged as an array
  def add_prod_data(sym, *values); end

  # Add a single value to prod_data, allows for values to be an array
  def add_prod_datum(sym, values); end

  def depth; end

  # @return [Integer] line number of current token
  def lineno; end

  # Initializes a new parser instance.
  #
  # Attempts to recover from errors.
  #
  # @example
  #   require 'rdf/ll1/parser'
  #
  #   class MyParser
  #   include EBNF::LL1::Parser
  #
  #   branch      MyParser::BRANCH
  #
  #   ##
  #   # Defines a production called during before parsing a non-terminal
  #   # with data from previous production along with data defined for the
  #   # current production
  #   #
  #   start_production :object do |input, current, callback|
  #   # Note production as triples for blankNodePropertyList
  #   # to set :subject instead of :resource
  #   current[:triples] = true
  #   end
  #
  #   ##
  #   # Defines a production called during after parsing a non-terminal
  #   # with data from previous production along with data defined for the
  #   # current production
  #   #
  #   # callback to processor block
  #   production :object do |input, current, callback|
  #   object = current[:resource]
  #   callback.call :statement, RDF::Statement.new(input[:subject], input[:predicate], object)
  #   end
  #
  #   ##
  #   # Defines the pattern for a terminal node
  #   terminal :BLANK_NODE_LABEL, %r(_:(#{PN_LOCAL})) do |production, token, input|
  #   input[:BLANK_NODE_LABEL] = RDF::Node.new(token)
  #   end
  #
  #   ##
  #   # Iterates the given block for each RDF statement in the input.
  #   #
  #   # @yield  [statement]
  #   # @yieldparam [RDF::Statement] statement
  #   # @return [void]
  #   def each_statement(&block)
  #   @callback = block
  #
  #   parse(input, START.to_sym) do |context, *data|
  #   case context
  #   when :statement
  #   yield *data
  #   end
  #   end
  #   end
  #
  #   end
  # @option options
  # @option options
  # @option options
  # @option options[Integer]
  # @option options
  # @option options[Integer]
  # @option options
  # @option options
  # @param input [String, #to_s]
  # @param start [Symbol, #to_s] The starting production for the parser. It may be a URI from the grammar, or a symbol representing the local_name portion of the grammar URI.
  # @param options [Hash{Symbol => Object}]
  # @param options[Integer] [Hash] a customizable set of options
  # @raise [Exception] Raises exceptions for parsing errors
  #   or errors raised during processing callbacks. Internal
  #   errors are raised using {Error}.
  # @return [EBNF::LL1::Parser]
  # @see https://cs.adelaide.edu.au/~charles/lt/Lectures/07-ErrorRecovery.pdf
  # @yield [context, *data] Yields for to return data to parser
  # @yieldparam context [:statement, :trace] Context for block
  # @yieldparam *data [Symbol] Data specific to the call
  def parse(input = T.unsafe(nil), start = T.unsafe(nil), **options, &block); end

  # Current ProdData element
  def prod_data; end

  protected

  # Debug logging.
  #
  # The call is ignored, unless `@options[:logger]` is set.
  #
  # @overload debug
  def debug(*args, &block); end

  # Error information, used as level `3` logger messages.
  # Messages may be logged and are saved for reporting at end of parsing.
  #
  # @option options
  # @option options
  # @param node [String] Relevant location associated with message
  # @param message [String] Error string
  # @param options [Hash{Symbol => Object}]
  # @see #debug
  def error(node, message, **options); end

  # Progress logged when parsing. Passed as level `1` logger messages.
  #
  # The call is ignored, unless `@options[:logger]` is set.
  #
  # @overload progress
  # @see #debug
  def progress(node, *args, &block); end

  # Warning information, used as level `2` logger messages.
  # Messages may be logged and are saved for reporting at end of parsing.
  #
  # @option options
  # @option options
  # @param node [String] Relevant location associated with message
  # @param message [String] Error string
  # @param options [Hash]
  # @see #debug
  def warn(node, message, **options); end

  private

  # Accept the first token in the input stream if it matches
  # `type\_or\_value`. Raise Error, otherwise.
  #
  # @param type_or_value [Symbol, String]
  # @raise [Error, Lexer::Error]
  # @return [Token]
  def accept(type_or_value); end

  # Does first include the specified token
  #
  # @param production [Symbol]
  # @param token [Symbol, Lexer::Token] A terminal, or symbol or string
  # @return [Boolean]
  def first_include?(production, token); end

  # Does follow include the specified terminal
  #
  # @param production [Symbol]
  # @param token [Symbol, Lexer::Token] A terminal, or symbol or string
  # @return [Boolean]
  def follow_include?(production, token); end

  # Return the next token, raising an error if the token is invalid
  #
  # @param recover [:recover] Recover from errors and go until next valid token or end of file
  # @raise [Lexer::Error]
  # @return [Token]
  def get_token(recover = T.unsafe(nil)); end

  # Finish of production
  def onFinish; end

  # Start for production
  def onStart(prod); end

  # A terminal
  def onTerminal(prod, token); end

  class << self
    # @private
    def included(base); end
  end
end

# DSL for creating terminals and productions
module EBNF::LL1::Parser::ClassMethods
  # Evaluate a handler, delegating to the specified object.
  # This is necessary so that handlers can operate within the
  # binding context of the parser in which they're invoked.
  #
  # @param object [Object]
  # @return [Object]
  def eval_with_binding(object); end

  def patterns; end

  # Defines a production called when production of associated
  # terminals and non-terminals has completed
  # with data from previous production along with data defined for the
  # current production. Block is called in an evaluation block from
  # the enclosing parser.
  #
  # Yield to generate a triple
  #
  # @param term [Symbol] Term which is a key in the branch table
  # @yield [input, current, block]
  # @yieldparam input [Hash] A Hash containing input from the parent production
  # @yieldparam current [Hash] A Hash defined for the current production, during :start
  #   may be initialized with data to pass to further productions,
  #   during :finish, it contains data placed by earlier productions
  # @yieldparam block [Proc] Block passed to initialization for yielding to calling parser.
  #   Should conform to the yield specs for #initialize
  def production(term, &block); end

  def production_handlers; end
  def start_handlers; end

  # Defines a production called at the beggining of a particular production
  # with data from previous production along with data defined for the
  # current production. Block is called in an evaluation block from
  # the enclosing parser.
  #
  # Yield to generate a triple
  #
  # @param term [Symbol] Term which is a key in the branch table
  # @yield [input, current, block]
  # @yieldparam input [Hash] A Hash containing input from the parent production
  # @yieldparam current [Hash] A Hash defined for the current production, during :start
  #   may be initialized with data to pass to further productions,
  #   during :finish, it contains data placed by earlier productions
  # @yieldparam block [Proc] Block passed to initialization for yielding to calling parser.
  #   Should conform to the yield specs for #initialize
  def start_production(term, &block); end

  # Defines the pattern for a terminal node and a block to be invoked
  # when ther terminal is encountered. If the block is missing, the
  # value of the terminal will be placed on the input hash to be returned
  # to a previous production. Block is called in an evaluation block from
  # the enclosing parser.
  #
  # @option options
  # @option options
  # @param term [Symbol, String] Defines a terminal production, which appears as within a sequence in the branch table
  # @param regexp [Regexp] Pattern used to scan for this terminal
  # @param options [Hash]
  # @yield [term, token, input, block]
  # @yieldparam term [Symbol] A symbol indicating the production which referenced this terminal
  # @yieldparam token [String] The scanned token
  # @yieldparam input [Hash] A Hash containing input from the parent production
  # @yieldparam block [Proc] Block passed to initialization for yielding to calling parser.
  #   Should conform to the yield specs for #initialize
  def terminal(term, regexp, **options, &block); end

  def terminal_handlers; end

  private

  def method_missing(method, *args, &block); end
end

# Raised for errors during parsing.
#
# @example Raising a parser error
#   raise Error.new(
#   "invalid token '%' on line 10",
#   token: '%', lineno: 9, production: :turtleDoc)
# @see https://ruby-doc.org/core/classes/StandardError.html
class EBNF::LL1::Parser::Error < ::StandardError
  # Initializes a new lexer error instance.
  #
  # @option options
  # @option options
  # @option options
  # @param message [String, #to_s]
  # @param options [Hash{Symbol => Object}]
  # @return [Error] a new instance of Error
  def initialize(message, **options); end

  # The line number where the error occurred.
  #
  # @return [Integer]
  def lineno; end

  # The current production.
  #
  # @return [Symbol]
  def production; end

  # The invalid token which triggered the error.
  #
  # @return [String]
  def token; end
end

# Overload StringScanner with file operations and line counting
#
# * Reloads scanner as required until EOF.
# * Loads to a high-water and reloads when remaining size reaches a low-water.
#
# FIXME: Only implements the subset required by the Lexer for now.
class EBNF::LL1::Scanner < ::StringScanner
  # Create a scanner, from an IO
  #
  # @option options[Integer]
  # @option options[Integer]
  # @param input [String, IO, #read]
  # @param options [Hash{Symbol => Object}]
  # @param options[Integer] [Hash] a customizable set of options
  # @return [Scanner]
  def initialize(input, **options); end

  # Ensures that the input buffer is full to the high water mark, or end of file. Useful when matching tokens that may be longer than the low water mark
  def ensure_buffer_full; end

  # Returns true if the scan pointer is at the end of the string
  #
  # @return [Boolean]
  def eos?; end

  # @return [String, IO, StringIO]
  def input; end

  # The current line number (one-based).
  #
  # @return [Integer]
  def lineno; end

  # The current line number (one-based).
  #
  # @return [Integer]
  def lineno=(_arg0); end

  # Returns the "rest" of the line, or the next line if at EOL (i.e. everything after the scan pointer).
  # If there is no more data (eos? = true), it returns "".
  #
  # @return [String]
  def rest; end

  # Tries to match with `pattern` at the current position.
  #
  # If there is a match, the scanner advances the "scan pointer" and returns the matched string.
  # Otherwise, the scanner returns nil.
  #
  # If the scanner begins with the multi-line start expression
  #
  # @example
  #   s = StringScanner.new('test string')
  #   p s.scan(/\w+/)   # -> "test"
  #   p s.scan(/\w+/)   # -> nil
  #   p s.scan(/\s+/)   # -> " "
  #   p s.scan(/\w+/)   # -> "string"
  #   p s.scan(/./)     # -> nil
  # @param pattern [Regexp]
  # @return [String]
  def scan(pattern); end

  # Scans the string until the pattern is matched. Returns the substring up to and including the end of the match, advancing the scan pointer to that location. If there is no match, nil is returned.
  #
  # @example
  #   s = StringScanner.new("Fri Dec 12 1975 14:39")
  #   s.scan_until(/1/)        # -> "Fri Dec 1"
  #   s.pre_match              # -> "Fri Dec "
  #   s.scan_until(/XYZ/)      # -> nil
  # @param pattern [Regexp]
  # @return [String]
  def scan_until(pattern); end

  # Attempts to skip over the given `pattern` beginning with the scan pointer.
  # If it matches, the scan pointer is advanced to the end of the match,
  # and the length of the match is returned. Otherwise, `nil` is returned.
  #
  # similar to `scan`, but without returning the matched string.
  #
  # @param pattern [Regexp]
  def skip(pattern); end

  # Advances the scan pointer until pattern is matched and consumed. Returns the number of bytes advanced, or nil if no match was found.
  #
  # Look ahead to match pattern, and advance the scan pointer to the end of the match. Return the number of characters advanced, or nil if the match was unsuccessful.
  #
  # Itâ€™s similar to scan_until, but without returning the intervening string.
  #
  # @param pattern [Regexp]
  def skip_until(pattern); end

  # Set the scan pointer to the end of the string and clear matching data
  def terminate; end

  # Sets the scan pointer to the previous position. Only one previous position is remembered, and it changes with each scanning operation.
  def unscan; end

  private

  # Perform UTF-8 encoding of input
  def encode_utf8(string); end

  # Maintain low-water mark
  def feed_me; end
end

# Hopefully large enough to deal with long multi-line comments
EBNF::LL1::Scanner::HIGH_WATER = T.let(T.unsafe(nil), Integer)

EBNF::LL1::Scanner::LOW_WATER = T.let(T.unsafe(nil), Integer)

module EBNF::Native
  # Parse alt
  #     >>> alt("a | b | c")
  #     ((alt a b c) '')
  #
  # @param s [String]
  # @return [Array]
  def alt(s); end

  # parse diff
  #
  #     >>> diff("a - b")
  #     ((diff a b) '')
  def diff(s); end

  # Native parser for EBNF; less accurate, but appropriate when changing EBNF grammar, itself.
  #
  # Iterate over rule strings.
  # a line that starts with '\[' or '@' starts a new rule
  #
  # @param scanner [StringScanner]
  # @yield rule_string
  # @yieldparam rule_string [String]
  def eachRule(scanner); end

  # Parse a string into an expression tree and a remaining string
  #
  # @example
  #   >>> expression("a b c")
  #   ((seq a b c) '')
  #
  #   >>> expression("a? b+ c*")
  #   ((seq (opt a) (plus b) (star c)) '')
  #
  #   >>> expression(" | x xlist")
  #   ((alt (seq) (seq x xlist)) '')
  #
  #   >>> expression("a | (b - c)")
  #   ((alt a (diff b c)) '')
  #
  #   >>> expression("a b | c d")
  #   ((alt (seq a b) (seq c d)) '')
  #
  #   >>> expression("a | b | c")
  #   ((alt a b c) '')
  #
  #   >>> expression("a) b c")
  #   (a ' b c')
  #
  #   >>> expression("BaseDecl? PrefixDecl*")
  #   ((seq (opt BaseDecl) (star PrefixDecl)) '')
  #
  #   >>> expression("NCCHAR1 | diff | [0-9] | #x00B7 | [#x0300-#x036F] | \[#x203F-#x2040\]")
  #   ((alt NCCHAR1 diff
  #   (range '0-9')
  #   (hex '#x00B7')
  #   (range '#x0300-#x036F')
  #   (range, '#x203F-#x2040')) '')
  # @param s [String]
  # @return [Array]
  def expression(s); end

  # parse postfix
  #
  #     >>> postfix("a b c")
  #     (a ' b c')
  #
  #     >>> postfix("a? b c")
  #     ((opt, a) ' b c')
  def postfix(s); end

  # parse primary
  #
  #     >>> primary("a b c")
  #     (a ' b c')
  def primary(s); end

  # Parse a rule into an optional rule number, a symbol and an expression
  #
  # @param rule [String]
  # @return [Rule]
  def ruleParts(rule); end

  # parse seq
  #
  #     >>> seq("a b c")
  #     ((seq a b c) '')
  #
  #     >>> seq("a b? c")
  #     ((seq a (opt b) c) '')
  def seq(s); end

  # parse one terminal; return the terminal and the remaining string
  #
  # A terminal is represented as a tuple whose 1st item gives the type;
  # some types have additional info in the tuple.
  #
  # @example
  #   >>> terminal("'abc' def")
  #   ('abc' ' def')
  #
  #   >>> terminal("[0-9]")
  #   ((range '0-9') '')
  #   >>> terminal("#x00B7")
  #   ((hex '#x00B7') '')
  #   >>> terminal ("\[#x0300-#x036F\]")
  #   ((range '#x0300-#x036F') '')
  #   >>> terminal("\[^<>'{}|^`\]-\[#x00-#x20\]")
  #   ((range "^<>'{}|^`") '-\[#x00-#x20\]')
  def terminal(s); end
end

module EBNF::PEG
  # Transform EBNF Rule set for PEG parsing:
  #
  #   * Transform each rule into a set of sub-rules extracting unnamed sequences into new rules, using {Rule#to_peg}.
  #
  # @return [ENBF] self
  def make_peg; end

  # Output Ruby parser files for PEG parsing
  #
  # @param output [IO, StringIO]
  def to_ruby_peg(output, **options); end
end

# A Generic PEG parser using the parsed rules modified for PEG parseing.
module EBNF::PEG::Parser
  mixes_in_class_methods ::EBNF::PEG::Parser::ClassMethods

  # Clear out packrat memoizer. This is appropriate when completing a top-level rule when there is no possibility of backtracking.
  def clear_packrat; end

  # Debug logging.
  #
  # The call is ignored, unless `@options[:logger]` is set.
  #
  # @overload debug
  def debug(*args, &block); end

  # Depth of parsing, for log output.
  def depth; end

  # Error information, used as level `3` logger messages.
  # Messages may be logged and are saved for reporting at end of parsing.
  #
  # @option options
  # @option options
  # @option options
  # @param node [String] Relevant location associated with message
  # @param message [String] Error string
  # @param options [Hash{Symbol => Object}]
  # @see #debug
  def error(node, message, **options); end

  # Find a rule for a symbol
  #
  # @param sym [Symbol]
  # @return [Rule]
  def find_rule(sym); end

  # Finish of production
  #
  # @param result [Object] parse result
  # @return [Object] parse result, or the value returned from the handler
  def onFinish(result); end

  # Start for production
  # Adds data avoiable during the processing of the production
  #
  # @return [Hash] composed of production options. Currently only `as_hash` is supported.
  # @see ClassMethods#start_production
  def onStart(prod); end

  # A terminal with a defined handler
  #
  # @param prod [Symbol] from the symbol of the associated rule
  # @param value [String] the scanned string
  # @return [String, Object] either the result from the handler, or the token
  def onTerminal(prod, value); end

  # A Hash structure used for memoizing rule results for a given input location.
  #
  #  @example Partial structure for memoizing results for a particular rule
  #
  #      {
  #        rule: {
  #          86: {
  #                pos:
  #                result: [<EBNF::Rule:80 {
  #                  sym: :ebnf,
  #                    id: "1",
  #                    kind: :rule,
  #                    expr: [:star, [:alt, :declaration, :rule]]}>],
  #               }
  #          131: [<EBNF::Rule:80 {sym: :ebnf,
  #              id: "1",
  #              kind: :rule,
  #              expr: [:star, [:alt, :declaration, :rule]]}>,
  #            <EBNF::Rule:100 {
  #              sym: :declaration,
  #              id: "2",
  #              kind: :rule,
  #              expr: [:alt, "@terminals", :pass]}>]
  #        },
  #        POSTFIX: {
  #          80: "*",
  #          368: "*",
  #          399: "+"
  #        }
  #      }
  #
  # @return [Hash{Integer => Hash{Symbol => Object}}]
  def packrat; end

  # Initializes a new parser instance.
  #
  # @option options[Integer]
  # @option options[Boolean]
  # @option options[Integer]
  # @option options
  # @option options
  # @param options[Boolean] [Hash] a customizable set of options
  # @param options [Hash{Symbol => Object}]
  # @param input [String, #to_s]
  # @param start [Symbol, #to_s] The starting production for the parser. It may be a URI from the grammar, or a symbol representing the local_name portion of the grammar URI.
  # @param rules [Array<EBNF::PEG::Rule>] The parsed rules, which control parsing sequence.
  #   Identify the symbol of the starting rule with `start`.
  # @param options[Integer] [Hash] a customizable set of options
  # @raise [Exception] Raises exceptions for parsing errors
  #   or errors raised during processing callbacks. Internal
  #   errors are raised using {Error}.
  # @return [Object] AST resulting from parse
  # @todo FIXME implement seq_hash
  # @yield [context, *data] Yields to return data to parser
  # @yieldparam context [:statement, :trace] Context for block
  # @yieldparam *data [Symbol] Data specific to the call
  def parse(input = T.unsafe(nil), start = T.unsafe(nil), rules = T.unsafe(nil), **options, &block); end

  # Current ProdData element
  def prod_data; end

  # Progress logged when parsing. Passed as level `1` logger messages.
  #
  # The call is ignored, unless `@options[:logger]` is set.
  #
  # @overload progress
  # @see #debug
  def progress(node, *args, &block); end

  # @return [Scanner] used for scanning input.
  def scanner; end

  # Find a regular expression defined for a terminal
  #
  # @param sym [Symbol]
  # @return [Regexp]
  def terminal_options(sym); end

  # Find a regular expression defined for a terminal
  #
  # @param sym [Symbol]
  # @return [Regexp]
  def terminal_regexp(sym); end

  # Record furthest failure.
  #
  # @param pos [Integer] The position in the input stream where the failure occured.
  # @param lineno [Integer] Line where the failure occured.
  # @param token [Symbol, String] The terminal token or string which attempted to match.
  # @see https://arxiv.org/pdf/1405.6646.pdf
  def update_furthest_failure(pos, lineno, token); end

  # Warning information, used as level `2` logger messages.
  # Messages may be logged and are saved for reporting at end of parsing.
  #
  # @option options
  # @option options
  # @param node [String] Relevant location associated with message
  # @param message [String] Error string
  # @param options [Hash]
  # @see #debug
  def warn(node, message, **options); end

  # @return [Regexp, Rule] how to remove inter-rule whitespace
  def whitespace; end

  class << self
    # @private
    def included(base); end
  end
end

# DSL for creating terminals and productions
module EBNF::PEG::Parser::ClassMethods
  # Evaluate a handler, delegating to the specified object.
  # This is necessary so that handlers can operate within the
  # binding context of the parser in which they're invoked.
  #
  # @param object [Object]
  # @return [Object]
  def eval_with_binding(object); end

  # Defines a production called when production of associated
  # non-terminals has completed
  # with data from previous production along with data defined for the
  # current production. Block is called in an evaluation block from
  # the enclosing parser.
  #
  # Yield to generate a triple
  #
  # @param term [Symbol] Term which is a key in the branch table
  # @param clear_packrat [Boolean] (false)
  #   Clears the packrat state on completion to reduce memory requirements of parser. Use only on a top-level rule when it is determined that no further backtracking is necessary.
  # @yield [result, data, block]
  # @yieldparam result [Object] The result from sucessfully parsing the production.
  # @yieldparam data [Hash] A Hash defined for the current production, during :start
  #   may be initialized with data to pass to further productions,
  #   during :finish, it contains data placed by earlier productions
  # @yieldparam block [Proc] Block passed to initialization for yielding to calling parser.
  #   Should conform to the yield specs for #initialize
  # @yieldreturn [Object] the result of this production.
  def production(term, clear_packrat: T.unsafe(nil), &block); end

  def production_handlers; end
  def start_handlers; end
  def start_options; end

  # Defines a production called at the beggining of a particular production
  # with data from previous production along with data defined for the
  # current production. Block is called in an evaluation block from
  # the enclosing parser.
  #
  # Yield to generate a triple
  #
  # @option options[:upper,
  # @option options
  # @param options [Hash{Symbol => Object}] Options which are returned from {Parser#onStart}.
  # @param options[:upper, [Hash] a customizable set of options
  # @param term [Symbol] The rule name
  # @yield [data, block]
  # @yieldparam data [Hash] A Hash defined for the current production, during :start
  #   may be initialized with data to pass to further productions,
  #   during :finish, it contains data placed by earlier productions
  # @yieldparam block [Proc] Block passed to initialization for yielding to calling parser.
  #   Should conform to the yield specs for #initialize
  def start_production(term, **options, &block); end

  # Defines the pattern for a terminal node and a block to be invoked
  # when ther terminal is encountered. If the block is missing, the
  # value of the terminal will be placed on the input hash to be returned
  # to a previous production. Block is called in an evaluation block from
  # the enclosing parser.
  #
  # If no block is provided, then the value which would have been passed to the block is used as the result directly.
  #
  # @option options
  # @param term [Symbol] The terminal name.
  # @param regexp [Regexp] (nil)
  #   Pattern used to scan for this terminal,
  #   defaults to the expression defined in the associated rule.
  #   If unset, the terminal rule is used for matching.
  # @param options [Hash]
  # @yield [value, prod]
  # @yieldparam value [String] The scanned terminal value.
  # @yieldparam prod [Symbol] A symbol indicating the production which referenced this terminal
  # @yieldparam block [Proc] Block passed to initialization for yielding to calling parser.
  #   Should conform to the yield specs for #initialize
  def terminal(term, regexp = T.unsafe(nil), **options, &block); end

  def terminal_handlers; end
  def terminal_options; end
  def terminal_regexps; end

  private

  def method_missing(method, *args, &block); end
end

# Raised for errors during parsing.
#
# @example Raising a parser error
#   raise Error.new(
#   "invalid token '%' on line 10",
#   rest: '%', lineno: 9, production: :turtleDoc)
# @see https://ruby-doc.org/core/classes/StandardError.html
class EBNF::PEG::Parser::Error < ::StandardError
  # Initializes a new lexer error instance.
  #
  # @option options
  # @option options
  # @option options
  # @param message [String, #to_s]
  # @param options [Hash{Symbol => Object}]
  # @return [Error] a new instance of Error
  def initialize(message, **options); end

  # The line number where the error occurred.
  #
  # @return [Integer]
  def lineno; end

  # The current production.
  #
  # @return [Symbol]
  def production; end

  # The read head when scanning failed
  #
  # @return [String]
  def rest; end
end

class EBNF::PEG::Parser::Unmatched < ::Struct
  def to_s; end
end

# Behaviior for parsing a PEG rule
module EBNF::PEG::Rule
  include ::EBNF::Unescape

  # Eat whitespace between non-terminal rules
  def eat_whitespace(input); end

  # If there is are `start_production` and/or `production`,
  # they are invoked with a `prod_data` stack, the input stream and offset.
  # Otherwise, the results are added as an array value
  # to a hash indexed by the rule name.
  #
  # If matched, the input position is updated and the results returned in a Hash.
  #
  # * `alt`: returns the value of the matched production or `:unmatched`.
  # * `diff`: returns the value matched, or `:unmatched`.
  # * `hex`: returns a string composed of the matched hex character, or `:unmatched`.
  # * `opt`: returns the value matched, or `nil` if unmatched.
  # * `plus`: returns an array of the values matched for the specified production, or `:unmatched`, if none are matched. For Terminals, these are concatenated into a single string.
  # * `range`: returns a string composed of the values matched, or `:unmatched`, if less than `min` are matched.
  # * `rept`: returns an array of the values matched for the speficied production, or `:unmatched`, if none are matched. For Terminals, these are concatenated into a single string.
  # * `seq`: returns an array composed of single-entry hashes for each matched production indexed by the production name, or `:unmatched` if any production fails to match. For Terminals, returns a string created by concatenating these values. Via option in a `production` or definition, the result can be a single hash with values for each matched production; note that this is not always possible due to the possibility of repeated productions within the sequence.
  # * `star`: returns an array of the values matched for the specified production. For Terminals, these are concatenated into a single string.
  #
  # @param input [Scanner]
  # @return [Hash{Symbol => Object}, :unmatched] A hash with keys for matched component of the expression. Returns :unmatched if the input does not match the production.
  def parse(input); end

  # Initialized by parser when loading rules.
  # Used for finding rules and invoking elements of the parse process.
  #
  # @return [EBNF::PEG::Parser] parser
  def parser; end

  # Initialized by parser when loading rules.
  # Used for finding rules and invoking elements of the parse process.
  #
  # @return [EBNF::PEG::Parser] parser
  def parser=(_arg0); end

  # Repitition, 0-1, 0-n, 1-n, ...
  #
  # Note, nil results are removed from the result, but count towards min/max calculations
  #
  # @param input [Scanner]
  # @param min [Integer]
  # @param max [Integer] If it is an integer, it stops matching after max entries.
  # @param prod [Symbol, String]
  # @param string_regexp_opts [Integer]
  # @return [:unmatched, Array]
  def rept(input, min, max, prod, string_regexp_opts, **options); end
end

class EBNF::Parser
  include ::EBNF::PEG::Parser
  include ::EBNF::Terminals
  extend ::EBNF::PEG::Parser::ClassMethods

  # ## Parser invocation.
  # On start, yield ourselves if a block is given, otherwise, return this parser instance
  #
  # @option options
  # @param input [#read, #to_s]
  # @param options [Hash{Symbol => Object}]
  # @return [EBNFParser]
  def initialize(input, **options, &block); end

  # Abstract syntax tree from parse
  #
  # @return [Array<EBNF::Rule>]
  def ast; end
end

# Represent individual parsed rules
class EBNF::Rule
  # @param sym [Symbol, nil] `nil` is allowed only for @pass or @terminals
  # @param id [Integer, nil]
  # @param expr [Array] The expression is an internal-representation of an S-Expression with one of the following oparators:
  #
  #   * `alt` â€“ A list of alternative rules, which are attempted in order. It terminates with the first matching rule, or is terminated as unmatched, if no such rule is found.
  #   * `diff` â€“ matches any string that matches `A` but does not match `B`.
  #   * `hex` â€“ A single character represented using the hexadecimal notation `#xnn`.
  #   * `istr` â€“ A string which matches in a case-insensitive manner, so that `(istr "fOo")` will match either of the strings `"foo"`, `"FOO"` or any other combination.
  #   * `opt` â€“ An optional rule or terminal. It either results in the matching rule or returns `nil`.
  #   * `plus` â€“ A sequence of one or more of the matching rule. If there is no such rule, it is terminated as unmatched; otherwise, the result is an array containing all matched input.
  #   * `range` â€“ A range of characters, possibly repeated, of the form `(range "a-z")`. May also use hexadecimal notation.
  #   * `rept m n` â€“ A sequence of at lest `m` and at most `n` of the matching rule. It will always return an array.
  #   * `seq` â€“ A sequence of rules or terminals. If any (other than `opt` or `star`) to not parse, the rule is terminated as unmatched.
  #   * `star` â€“ A sequence of zero or more of the matching rule. It will always return an array.
  # @param kind [:rule, :terminal, :terminals, :pass] (nil)
  # @param ebnf [String] (nil)
  #   When parsing, records the EBNF string used to create the rule.
  # @param first [Array] (nil)
  #   Recorded set of terminals that can proceed this rule (LL(1))
  # @param follow [Array] (nil)
  #   Recorded set of terminals that can follow this rule (LL(1))
  # @param start [Boolean] (nil)
  #   Is this the starting rule for the grammar?
  # @param top_rule [Rule] (nil)
  #   The top-most rule. All expressed rules are top-rules, derived rules have the original rule as their top-rule.
  # @param cleanup [Boolean] (nil)
  #   Records information useful for cleaning up converted :plus, and :star expansions (LL(1)).
  # @raise [ArgumentError]
  # @return [Rule] a new instance of Rule
  def initialize(sym, id, expr, kind: T.unsafe(nil), ebnf: T.unsafe(nil), first: T.unsafe(nil), follow: T.unsafe(nil), start: T.unsafe(nil), top_rule: T.unsafe(nil), cleanup: T.unsafe(nil)); end

  # Rules compare using their ids
  def <=>(other); end

  # Two rules are equal if they have the same {#sym}, {#kind} and {#expr}.
  #
  # @param other [Rule]
  # @return [Boolean]
  def ==(other); end

  # Add terminal as proceding this rule.
  #
  # @param terminals [Array<Rule, Symbol, String>]
  # @return [Integer] if number of terminals added
  def add_first(terminals); end

  # Add terminal as following this rule. Don't add _eps as a follow
  #
  # @param terminals [Array<Rule, Symbol, String>]
  # @return [Integer] if number of terminals added
  def add_follow(terminals); end

  # Is this rule of the form (alt ...)?
  #
  # @return [Boolean]
  def alt?; end

  # Build a new rule creating a symbol and numbering from the current rule
  # Symbol and number creation is handled by the top-most rule in such a chain.
  #
  # @param expr [Array]
  # @param kind [Symbol] (nil)
  # @param cleanup [Hash{Symbol => Symbol}] (nil)
  # @param options [Hash{Symbol => Object}]
  def build(expr, kind: T.unsafe(nil), cleanup: T.unsafe(nil), **options); end

  # Determines preparation and cleanup rules for reconstituting EBNF ? * + from BNF
  def cleanup; end

  # Determines preparation and cleanup rules for reconstituting EBNF ? * + from BNF
  def cleanup=(_arg0); end

  # A comprehension is a sequence which contains all elements but the first of the original rule.
  #
  # @return [Rule]
  def comp; end

  # A comprehension is a sequence which contains all elements but the first of the original rule.
  #
  # @return [Rule]
  def comp=(_arg0); end

  # Two rules are equivalent if they have the same {#expr}.
  #
  # @param other [Rule]
  # @return [Boolean]
  def eql?(other); end

  # Rule expression
  #
  # @return [Array]
  def expr; end

  # Rule expression
  #
  # @return [Array]
  def expr=(_arg0); end

  # Terminals that immediately procede this rule
  #
  # @return [Array<Rule>]
  def first; end

  # Do the firsts of this rule include the empty string?
  #
  # @return [Boolean]
  def first_includes_eps?; end

  # Terminals that immediately follow this rule
  #
  # @return [Array<Rule>]
  def follow; end

  # Return representation for building S-Expressions.
  #
  # @return [Array]
  def for_sxp; end

  # ID of rule
  #
  # @return [String]
  def id; end

  # ID of rule
  #
  # @return [String]
  def id=(_arg0); end

  def inspect; end

  # Kind of rule
  #
  # @return [:rule, :terminal, :terminals, or :pass]
  def kind; end

  # Kind of rule
  #
  # @return [:rule, :terminal, :terminals, or :pass]
  def kind=(_arg0); end

  # Return the non-terminals for this rule.
  #
  # * `alt` => this is every non-terminal.
  # * `diff` => this is every non-terminal.
  # * `hex` => nil
  # * `istr` => nil
  # * `not` => this is the last expression, if any.
  # * `opt` => this is the last expression, if any.
  # * `plus` => this is the last expression, if any.
  # * `range` => nil
  # * `rept` => this is the last expression, if any.
  # * `seq` => this is the first expression in the sequence, if any.
  # * `star` => this is the last expression, if any.
  #
  # @note this is used for LL(1) tansformation, so rule types are limited
  # @param ast [Array<Rule>] The set of rules, used to turn symbols into rules
  # @param expr [Array<Symbol,String,Array>] (@expr)
  #   The expression to check, defaults to the rule expression.
  #   Typically, if the expression is recursive, the embedded expression is called recursively.
  # @return [Array<Rule>]
  def non_terminals(ast, expr = T.unsafe(nil)); end

  # Original EBNF
  #
  # @return [String]
  def orig; end

  # Original EBNF
  #
  # @return [String]
  def orig=(_arg0); end

  # Is this a pass?
  #
  # @return [Boolean]
  def pass?; end

  # Is this a rule?
  #
  # @return [Boolean]
  def rule?; end

  # Is this rule of the form (seq ...)?
  #
  # @return [Boolean]
  def seq?; end

  # Indicates that this is a starting rule
  #
  # @return [Boolean]
  def start; end

  # Indicates that this is a starting rule
  #
  # @return [Boolean]
  def start=(_arg0); end

  # Does this rule start with `sym`? It does if expr is that sym,
  # expr starts with alt and contains that sym,
  # or expr starts with seq and the next element is that sym.
  #
  # @param sym [Symbol, class] Symbol matching any start element, or if it is String, any start element which is a String
  # @return [Array<Symbol, String>] list of symbol (singular), or strings which are start symbol, or nil if there are none
  def starts_with?(sym); end

  # Symbol of rule
  #
  # @return [Symbol]
  def sym; end

  # Symbol of rule
  #
  # @return [Symbol]
  def sym=(_arg0); end

  # Return the symbols used in the rule.
  #
  # @param expr [Array<Symbol,String,Array>] (@expr)
  #   The expression to check, defaults to the rule expression.
  #   Typically, if the expression is recursive, the embedded expression is called recursively.
  # @return [Array<Rule>]
  def symbols(expr = T.unsafe(nil)); end

  # Is this a terminal?
  #
  # @return [Boolean]
  def terminal?; end

  # Return the terminals for this rule.
  #
  # * `alt` => this is every terminal.
  # * `diff` => this is every terminal.
  # * `hex` => nil
  # * `istr` => nil
  # * `not` => this is the last expression, if any.
  # * `opt` => this is the last expression, if any.
  # * `plus` => this is the last expression, if any.
  # * `range` => nil
  # * `rept` => this is the last expression, if any.
  # * `seq` => this is the first expression in the sequence, if any.
  # * `star` => this is the last expression, if any.
  #
  # @note this is used for LL(1) tansformation, so rule types are limited
  # @param ast [Array<Rule>] The set of rules, used to turn symbols into rules
  # @param expr [Array<Symbol,String,Array>] (@expr)
  #   The expression to check, defaults to the rule expression.
  #   Typically, if the expression is recursive, the embedded expression is called recursively.
  # @return [Array<Rule>]
  def terminals(ast, expr = T.unsafe(nil)); end

  # Transform EBNF rule to BNF rules:
  #
  #   * Transform `(rule a "n" (op1 (op2)))` into two rules:
  #
  #         (rule a "n" (op1 _a_1))
  #         (rule _a_1 "n.1" (op2))
  #   * Transform `(rule a (opt b))` into `(rule a (alt _empty b))`
  #   * Transform `(rule a (star b))` into `(rule a (alt _empty (seq b a)))`
  #   * Transform `(rule a (plus b))` into `(rule a (seq b (star b)`
  #
  # Transformation includes information used to re-construct non-transformed.
  #
  # AST representation
  #
  # @return [Array<Rule>]
  def to_bnf; end

  # Transform EBNF rule for PEG:
  #
  #   * Transform `(rule a "n" (op1 ... (op2 y) ...z))` into two rules:
  #
  #         (rule a "n" (op1 ... _a_1 ... z))
  #         (rule _a_1 "n.1" (op2 y))
  #   * Transform `(rule a "n" (diff op1 op2))` into two rules:
  #
  #         (rule a "n" (seq _a_1 op1))
  #         (rule _a_1 "n.1" (not op1))
  #
  # @return [Array<Rule>]
  def to_peg; end

  # For :hex or :range, create a regular expression.
  #
  # @return [Regexp]
  def to_regexp; end

  # Return a Ruby representation of this rule
  #
  # @return [String]
  def to_ruby; end

  # Return SXP representation of this rule
  #
  # @return [String]
  def to_s(**options); end

  # Return SXP representation of this rule
  #
  # @return [String]
  def to_sxp(**options); end

  # Serializes this rule to an Turtle.
  #
  # @return [String]
  def to_ttl; end

  # Utility function to translate code points of the form '#xN' into ruby unicode characters
  def translate_codepoints(str); end

  # Validate the rule, with respect to an AST.
  #
  # Uses `#validate!` and catches `RangeError`
  #
  # @param ast [Array<Rule>] The set of rules, used to turn symbols into rules
  # @return [Boolean]
  def valid?(ast); end

  # Validate the rule, with respect to an AST.
  #
  # @param ast [Array<Rule>] The set of rules, used to turn symbols into rules
  # @param expr [Array<Symbol,String,Array>] (@expr)
  #   The expression to check, defaults to the rule expression.
  #   Typically, if the expression is recursive, the embedded expression is called recursively.
  # @raise [RangeError]
  def validate!(ast, expr = T.unsafe(nil)); end

  private

  # turn an XML BNF character class into an N3 literal for that
  # character class (less the outer quote marks)
  #
  #     >>> cclass("^<>'{}|^`")
  #     "[^<>'{}|^`]"
  #     >>> cclass("#x0300-#x036F")
  #     "[\\u0300-\\u036F]"
  #     >>> cclass("#xC0-#xD6")
  #     "[\\u00C0-\\u00D6]"
  #     >>> cclass("#x370-#x37D")
  #     "[\\u0370-\\u037D]"
  #
  #     as in: ECHAR ::= '\' [tbnrf\"']
  #     >>> cclass("tbnrf\\\"'")
  #     'tbnrf\\\\\\"\''
  #
  #     >>> cclass("^#x22#x5C#x0A#x0D")
  #     '^\\u0022\\\\\\u005C\\u000A\\u000D'
  def cclass(txt); end

  # Escape "[", "]", and "\" in ranges so they don't result in a warning or error
  # about empty character classes.
  def escape_regexp_character_range(character_range); end

  # Make a new symbol/number combination
  #
  # @param variation [String] added to symbol to aid reconstitution from BNF to EBNF
  def make_sym_id(variation = T.unsafe(nil)); end

  def ttl_expr(expr, pfx, depth, is_obj = T.unsafe(nil)); end

  class << self
    # Return a rule from its SXP representation:
    #
    # Also may have `(first ...)`, `(follow ...)`, or `(start #t)`.
    #
    # @example inputs
    #   (pass _pass (plus (range "#x20\\t\\r\\n")))
    #   (rule ebnf "1" (star (alt declaration rule)))
    #   (terminal R_CHAR "19" (diff CHAR (alt "]" "-")))
    # @param sxp [String, Array]
    # @return [Rule]
    def from_sxp(sxp); end
  end
end

# Operations which are flattened to seprate rules in to_bnf.
EBNF::Rule::BNF_OPS = T.let(T.unsafe(nil), Array)

# The number of arguments expected per operator. `nil` for unspecified
EBNF::Rule::OP_ARGN = T.let(T.unsafe(nil), Hash)

EBNF::Rule::TERM_OPS = T.let(T.unsafe(nil), Array)

# Terminal definitions for the EBNF grammar
module EBNF::Terminals; end

EBNF::Terminals::CHAR = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::HEX = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::LHS = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::O_RANGE = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::PASS = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::POSTFIX = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::RANGE = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::R_CHAR = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::STRING1 = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::STRING2 = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::SYMBOL = T.let(T.unsafe(nil), Regexp)
EBNF::Terminals::SYMBOL_BASE = T.let(T.unsafe(nil), Regexp)

# Unsecape strings
module EBNF::Unescape
  private

  # Perform string and codepoint unescaping if defined for this terminal
  #
  # @param string [String]
  # @return [String]
  def unescape(string); end

  # Returns a copy of the given `input` string with all `\uXXXX` and
  # `\UXXXXXXXX` Unicode codepoint escape sequences replaced with their
  # unescaped UTF-8 character counterparts.
  #
  # @param string [String]
  # @return [String]
  # @see https://www.w3.org/TR/rdf-sparql-query/#codepointEscape
  def unescape_codepoints(string); end

  # Returns a copy of the given `input` string with all string escape
  # sequences (e.g. `\n` and `\t`) replaced with their unescaped UTF-8
  # character counterparts.
  #
  # @param input [String]
  # @return [String]
  # @see https://www.w3.org/TR/rdf-sparql-query/#grammarEscapes
  def unescape_string(input); end

  class << self
    # Perform string and codepoint unescaping if defined for this terminal
    #
    # @param string [String]
    # @return [String]
    def unescape(string); end

    # Returns a copy of the given `input` string with all `\uXXXX` and
    # `\UXXXXXXXX` Unicode codepoint escape sequences replaced with their
    # unescaped UTF-8 character counterparts.
    #
    # @param string [String]
    # @return [String]
    # @see https://www.w3.org/TR/rdf-sparql-query/#codepointEscape
    def unescape_codepoints(string); end

    # Returns a copy of the given `input` string with all string escape
    # sequences (e.g. `\n` and `\t`) replaced with their unescaped UTF-8
    # character counterparts.
    #
    # @param input [String]
    # @return [String]
    # @see https://www.w3.org/TR/rdf-sparql-query/#grammarEscapes
    def unescape_string(input); end
  end
end

# More liberal unescaping
EBNF::Unescape::ECHAR = T.let(T.unsafe(nil), Regexp)

# \u005C (backslash)
EBNF::Unescape::ESCAPE_CHAR4 = T.let(T.unsafe(nil), Regexp)

# \UXXXXXXXX
EBNF::Unescape::ESCAPE_CHAR8 = T.let(T.unsafe(nil), Regexp)

EBNF::Unescape::ESCAPE_CHARS = T.let(T.unsafe(nil), Hash)
EBNF::Unescape::UCHAR = T.let(T.unsafe(nil), Regexp)

module EBNF::VERSION
  class << self
    # @return [Array(Integer, Integer, Integer)]
    def to_a; end

    # @return [String]
    def to_s; end

    # @return [String]
    def to_str; end
  end
end

EBNF::VERSION::MAJOR = T.let(T.unsafe(nil), String)
EBNF::VERSION::MINOR = T.let(T.unsafe(nil), String)
EBNF::VERSION::STRING = T.let(T.unsafe(nil), String)
EBNF::VERSION::TINY = T.let(T.unsafe(nil), String)
EBNF::VERSION::VERSION_FILE = T.let(T.unsafe(nil), String)

class EBNF::Writer
  # @param rules [Array<Rule>]
  # @param format [:abnf, :ebnf, :isoebnf] (:ebnf)
  # @param html [Boolean] (false) generate HTML output
  # @param validate [Boolean] (false) validate generated HTML.
  # @param options [Hash{Symbol => Object}]
  # @param out [#write] ($stdout)
  # @return [Writer] a new instance of Writer
  def initialize(rules, out: T.unsafe(nil), html: T.unsafe(nil), format: T.unsafe(nil), validate: T.unsafe(nil), **options); end

  protected

  def escape_abnf_hex(u); end
  def escape_ebnf_hex(u); end

  # Format the expression part of a rule
  def format_abnf(expr, sep: T.unsafe(nil), embedded: T.unsafe(nil), sensitive: T.unsafe(nil)); end

  # Format a single-character string, prefering hex for non-main ASCII
  def format_abnf_char(c); end

  # Format a range
  #
  # Presumes range has already been validated
  #
  # @raise [RangeError]
  def format_abnf_range(string); end

  # Format the expression part of a rule
  def format_ebnf(expr, sep: T.unsafe(nil), embedded: T.unsafe(nil)); end

  # Format a single-character string, prefering hex for non-main ASCII
  def format_ebnf_char(c); end

  # Format a range
  def format_ebnf_range(string); end

  # Escape a string, using as many UTF-8 characters as possible
  def format_ebnf_string(string, quote = T.unsafe(nil)); end

  # Format the expression part of a rule
  def format_isoebnf(expr, sep: T.unsafe(nil), embedded: T.unsafe(nil)); end

  # Format a range
  # Range is formatted as a aliteration of characters
  #
  # @raise [RangeError]
  def format_isoebnf_range(string); end

  class << self
    # Write formatted rules to an IO like object as HTML
    #
    # @param rules [Array<Rule>]
    # @param format [:abnf, :ebnf, :isoebnf] (:ebnf)
    # @param validate [Boolean] (false) validate generated HTML.
    # @return [Object]
    def html(*rules, format: T.unsafe(nil), validate: T.unsafe(nil)); end

    # Format rules to $stdout
    #
    # @param rules [Array<Rule>]
    # @param format [:abnf, :ebnf, :isoebnf] (:ebnf)
    # @return [Object]
    def print(*rules, format: T.unsafe(nil)); end

    # Format rules to a String
    #
    # @param rules [Array<Rule>]
    # @param format [:abnf, :ebnf, :isoebnf] (:ebnf)
    # @return [Object]
    def string(*rules, format: T.unsafe(nil)); end

    # Write formatted rules to an IO like object
    #
    # @param out [Object]
    # @param rules [Array<Rule>]
    # @param format [:abnf, :ebnf, :isoebnf] (:ebnf)
    # @return [Object]
    def write(out, *rules, format: T.unsafe(nil)); end
  end
end

# ASCII escape names
EBNF::Writer::ASCII_ESCAPE_NAMES = T.let(T.unsafe(nil), Array)

EBNF::Writer::ERB_DESC = T.let(T.unsafe(nil), String)
EBNF::Writer::LINE_LENGTH = T.let(T.unsafe(nil), Integer)
EBNF::Writer::LINE_LENGTH_HTML = T.let(T.unsafe(nil), Integer)

# This file is automatically generated by ebnf version 2.0.0
# Derived from etc/ebnf.ebnf
module EBNFMeta; end

EBNFMeta::RULES = T.let(T.unsafe(nil), Array)

# This file is automatically generated by ebnf version 2.0.0
# Derived from etc/iso-ebnf.ebnf
module ISOEBNFMeta; end

ISOEBNFMeta::RULES = T.let(T.unsafe(nil), Array)
